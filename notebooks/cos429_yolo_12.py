# -*- coding: utf-8 -*-
"""COS429_YOLO_12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d8WFBQvg4T7aoAmAXVmpU8kwFiptlOXE
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

"""We collect 203 images of snack configurations in different environments to create our initial dataset.
Using Label Studio, we label images with bounding box locations and classifcation labels.

Classes:
- oreos
- milano cookies
- swedish fish
- sour patch kids
- roasted chestnut
- popcorn
- pretzel crisps

Raw dataset: https://drive.google.com/drive/folders/1T3vnQXzSPbPWz49-BLK_EzKcv2DYO3uZ?usp=drive_link
Labeled dataset: https://drive.google.com/drive/folders/1lQnCvHbG4y3RoeEweDaNM9QXAyLaSOwQ?usp=drive_link
"""

!uv pip install ultralytics

# import dependencies
import os
import random
import shutil
import yaml
import glob
from collections import defaultdict

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import cv2

from IPython.display import Image, display

# unzip labeled data in yolo format
!unzip -q /content/drive/MyDrive/COS429FinalProject/data_aug_2.zip -d /content/

# config
DATAPATH = "/content/data"
CLASSES_PATH = "/content/data/classes.txt"
YAML_PATH = "/content/data.yaml"

TRAIN_FRAC = 0.80
VAL_FRAC   = 0.10
TEST_FRAC  = 0.10

SEED = 123
SIMILARITY_AWARE = True
PHASH_THRESHOLD = 10
COPY_INSTEAD_OF_MOVE = True
RESET_SPLITS = True
#run calorie:
EVAL_SPLIT_FOR_CALORIES = "test"

# Similarity-aware grouping
def _phash_int(img_path, hash_size=8, highfreq_factor=4):
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        raise ValueError(f"Could not read image: {img_path}")

    size = hash_size * highfreq_factor
    img = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)
    img = np.float32(img)

    dct = cv2.dct(img)
    dct_low = dct[:hash_size, :hash_size]

    med = np.median(dct_low[1:, 1:])
    bits = (dct_low > med).flatten()

    h = 0
    for b in bits:
        h = (h << 1) | int(b)
    return h

def _hamming(a, b):
    return (a ^ b).bit_count()

class _UnionFind:
    def __init__(self, items):
        self.parent = {x: x for x in items}
        self.rank = {x: 0 for x in items}

    def find(self, x):
        while self.parent[x] != x:
            self.parent[x] = self.parent[self.parent[x]]
            x = self.parent[x]
        return x

    def union(self, a, b):
        ra, rb = self.find(a), self.find(b)
        if ra == rb:
            return
        if self.rank[ra] < self.rank[rb]:
            self.parent[ra] = rb
        elif self.rank[ra] > self.rank[rb]:
            self.parent[rb] = ra
        else:
            self.parent[rb] = ra
            self.rank[ra] += 1

def split_train_val_test(
    datapath,
    train_frac=0.8,
    val_frac=0.1,
    test_frac=0.1,
    seed=42,
    similarity_aware=True,
    phash_threshold=10,
    copy_instead_of_move=True,
    reset_splits=True,
):
    assert abs((train_frac + val_frac + test_frac) - 1.0) < 1e-9

    images_root = os.path.join(datapath, "images")
    labels_root = os.path.join(datapath, "labels")

    exts = (".jpg", ".jpeg", ".png")
    image_files = sorted([f for f in os.listdir(images_root) if f.lower().endswith(exts)])
    print(f"dataset size: {len(image_files)}")

    if reset_splits:
        for split in ["train", "val", "test"]:
            shutil.rmtree(os.path.join(datapath, split), ignore_errors=True)

    for split in ["train", "val", "test"]:
        os.makedirs(os.path.join(datapath, split, "images"), exist_ok=True)
        os.makedirs(os.path.join(datapath, split, "labels"), exist_ok=True)

    rng = random.Random(seed)

    if not similarity_aware:
        groups = [[f] for f in image_files]
        rng.shuffle(groups)
    else:
        hashes = {}
        for f in image_files:
            hashes[f] = _phash_int(os.path.join(images_root, f))

        uf = _UnionFind(image_files)
        n = len(image_files)

        for i in range(n):
            fi = image_files[i]
            for j in range(i + 1, n):
                fj = image_files[j]
                if _hamming(hashes[fi], hashes[fj]) <= phash_threshold:
                    uf.union(fi, fj)

        comps = defaultdict(list)
        for f in image_files:
            comps[uf.find(f)].append(f)

        groups = list(comps.values())
        rng.shuffle(groups)

        big = sorted([g for g in groups if len(g) > 1], key=len, reverse=True)
        if big:
            print("Similarity clusters (size>1):", [len(g) for g in big[:10]], "...")
        print(f"Total groups after clustering: {len(groups)}")

    total = len(image_files)
    target_train = int(round(total * train_frac))
    target_val = int(round(total * val_frac))

    split_files = {"train": [], "val": [], "test": []}
    counts = {"train": 0, "val": 0, "test": 0}

    # Greedy fill
    for g in groups:
        if counts["train"] + len(g) <= target_train:
            split = "train"
        elif counts["val"] + len(g) <= target_val:
            split = "val"
        else:
            split = "test"
        split_files[split].extend(g)
        counts[split] += len(g)

    print("Split counts:", counts)

    copier = shutil.copy2 if copy_instead_of_move else shutil.move

    label_files = set([f for f in os.listdir(labels_root) if f.endswith(".txt")])

    for split, files in split_files.items():
        for f in files:
            base = os.path.splitext(f)[0]
            src_img = os.path.join(images_root, f)
            dst_img = os.path.join(datapath, split, "images", f)
            copier(src_img, dst_img)

            src_lbl = os.path.join(labels_root, base + ".txt")
            dst_lbl = os.path.join(datapath, split, "labels", base + ".txt")

            if os.path.exists(src_lbl):
                copier(src_lbl, dst_lbl)
            else:
                open(dst_lbl, "a").close()

    return split_files

split_train_val_test(
    datapath=DATAPATH,
    train_frac=TRAIN_FRAC,
    val_frac=VAL_FRAC,
    test_frac=TEST_FRAC,
    seed=SEED,
    similarity_aware=SIMILARITY_AWARE,
    phash_threshold=PHASH_THRESHOLD,
    copy_instead_of_move=COPY_INSTEAD_OF_MOVE,
    reset_splits=RESET_SPLITS,
)

# prepare data.yaml for training
def prepare_data_yaml(class_path, yaml_path):
    with open(class_path, "r") as f:
        classes = [line.strip() for line in f if line.strip()]

    data = {
        "path": "/content/data",
        "train": "train/images",
        "val": "val/images",
        "test": "test/images",
        "nc": len(classes),
        "names": classes,
    }

    with open(yaml_path, "w") as f:
        yaml.dump(data, f, sort_keys=False)

prepare_data_yaml(CLASSES_PATH, YAML_PATH)

# train yolo model
!yolo detect train model=yolo11l.pt data=/content/data.yaml epochs=50 imgsz=640

# helper to find latest train run + best weights + results.csv
def _latest_by_mtime(paths):
    paths = [p for p in paths if os.path.exists(p)]
    if not paths:
        return None
    return max(paths, key=lambda p: os.path.getmtime(p))

def find_latest_train_run(base="/content/runs/detect"):
    run_dirs = sorted(glob.glob(os.path.join(base, "train*")))
    return _latest_by_mtime(run_dirs)

train_run = find_latest_train_run()
print("Latest train run:", train_run)

results_csv = os.path.join(train_run, "results.csv") if train_run else None
best_pt = os.path.join(train_run, "weights", "best.pt") if train_run else None

print("results.csv:", results_csv)
print("best.pt:", best_pt)

# plot training loss
if results_csv and os.path.exists(results_csv):
    df = pd.read_csv(results_csv)

    plt.figure(figsize=(8, 5))
    if "train/box_loss" in df.columns: plt.plot(df["epoch"], df["train/box_loss"], label="Bounding Box Loss")
    if "train/cls_loss" in df.columns: plt.plot(df["epoch"], df["train/cls_loss"], label="Classification Loss")
    if "train/dfl_loss" in df.columns: plt.plot(df["epoch"], df["train/dfl_loss"], label="DFL Loss")

    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title("Training Loss")
    plt.legend()
    plt.grid(True)
    plt.show()
else:
    print("Could not find results.csv to plot.")

# evaluate and visualize predictions
if best_pt and os.path.exists(best_pt):
    !yolo detect predict model={best_pt} source=/content/data/val/images save=True
else:
    print("Could not find best.pt for prediction.")

def find_latest_predict_run(base="/content/runs/detect"):
    run_dirs = sorted(glob.glob(os.path.join(base, "predict*")))
    return _latest_by_mtime(run_dirs)

pred_run = find_latest_predict_run()
print("Latest predict run:", pred_run)

if pred_run:
    for image_path in glob.glob(os.path.join(pred_run, "*.jpg"))[:]:
        display(Image(filename=image_path, height=600))
        print("\n")

# calorie estimation
calories = {
    "milano cookie": 65,      # per cookie
    "oreo": 70,               # per cookie
    "popcorn": 2.25,          # per one popcorn
    "pretzel crisp": 10,      # per crisp
    "roasted chestnut": 20,   # per chestnut
    "sour patch kid": 9,      # per candy
    "swedish fish": 22        # per candy
}

from ultralytics import YOLO

if best_pt and os.path.exists(best_pt):
    model = YOLO(best_pt)

    eval_dir = f"/content/data/{EVAL_SPLIT_FOR_CALORIES}/images"
    image_paths = sorted(glob.glob(os.path.join(eval_dir, "*.jpg")) +
                         glob.glob(os.path.join(eval_dir, "*.jpeg")) +
                         glob.glob(os.path.join(eval_dir, "*.png")))

    print(f"Total {EVAL_SPLIT_FOR_CALORIES} images: {len(image_paths)}")

    for img_path in image_paths:
        results = model(img_path)[0]

        item_counts = {}
        for box in results.boxes:
            cls_id = int(box.cls)
            cls_name = model.names[cls_id]
            item_counts[cls_name] = item_counts.get(cls_name, 0) + 1

        total_cal = 0
        per_item_info = []
        for item, count in item_counts.items():
            if item not in calories:
                continue
            item_cal = calories[item] * count
            total_cal += item_cal
            per_item_info.append(f"{item}: {count} Ã— {calories[item]} = {item_cal} cal")

        print(f"\nImage: {os.path.basename(img_path)}")
        display(Image(filename=img_path, width=500))

        if per_item_info:
            print("Calories in image:")
            for line in per_item_info:
                print("  " + line)
            print(f"Total calories: {total_cal} cal")
        else:
            print("No calorie-mapped items detected.")
else:
    print("Could not find best.pt for calorie demo.")
